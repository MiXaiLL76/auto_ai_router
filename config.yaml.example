server:
  port: 8080
  max_body_size_mb: 100
  request_timeout: 90s
  logging_level: info  # Options: info, debug, error
  master_key: "sk-your-master-key-here"  # Required: Master key for authentication
  default_models_rpm: 50  # Default RPM limit for models (use -1 for unlimited)

fail2ban:
  max_attempts: 3
  ban_duration: permanent
  error_codes: [401, 403, 429, 500, 502, 503, 504]

monitoring:
  prometheus_enabled: true
  health_check_path: "/health"
  log_errors: false
  errors_log_path: "logs/logs.jsonl"

credentials:
  # Direct provider credentials
  - name: "openai_main"
    type: "openai"
    api_key: "sk-proj-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"
    base_url: "https://api.openai.com"
    rpm: 100
    tpm: 50000

  - name: "vertex_ai"
    type: "vertex-ai"
    project_id: "your-project-id"
    location: "global"
    credentials_file: "path/to/service-account.json"
    rpm: 100
    tpm: 50000

  # Proxy credential (forwards requests to another auto_ai_router instance)
  - name: "proxy_fallback"
    type: "proxy"
    base_url: "http://backup-router.local:8080"  # URL of remote auto_ai_router
    api_key: "sk-remote-master-key"  # Optional: remote master key
    rpm: 200
    tpm: 100000
    is_fallback: true  # Use as fallback when primary credentials are exhausted

# Optional: Models with specific credential binding
models:
  - name: "gpt-4o"
    credential: openai_main
    rpm: 100
    tpm: 50000
  - name: "gemini-2.5-pro"
    credential: vertex_ai
    rpm: 100
    tpm: 50000
