server:
  port: 8080
  max_body_size_mb: 100
  request_timeout: 30s
  logging_level: debug  # Options: info, debug, error
  replace_v1_models: true
  master_key: "sk-your-master-key-here"  # Required: Master key for client authentication
  default_models_rpm: 50  # Default RPM limit for models (used if not specified in models.yaml)

fail2ban:
  max_attempts: 3
  ban_duration: permanent
  error_codes: [401, 403, 429, 500, 502, 503, 504]

credentials:
  - name: "openai_main"
    type: "openai"
    api_key: "sk-proj-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"
    base_url: "https://api.openai.com"
    rpm: 100   # Requests per minute limit for this credential (use -1 for unlimited)
    tpm: 50000 # Tokens per minute limit for this credential (use 0 or -1 for unlimited)

  - name: "openai_backup"
    type: "openai"
    api_key: "sk-proj-yyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyy"
    base_url: "https://api.openai.com"
    rpm: 50
    tpm: 25000

monitoring:
  prometheus_enabled: true
  health_check_path: "/health"
